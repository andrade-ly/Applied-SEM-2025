---
title: "ESEM in R"
Author: "Fernanda Andrade"
output: 
  pdf_document:
#    css: style.css
  
---

```{r setup, include=FALSE}
options(width=90)
knitr::opts_chunk$set(
  echo = T,
  message = FALSE,
  warning = FALSE,
  tidy = TRUE
)
```

```{r, include=FALSE}
library(BifactorIndicesCalculator)
library(lavaan)
library(tidyverse)
library(dplyr)
library(psych)
library(semTools)
library(GPArotation)
```

```{r, include=FALSE}
habit <- read.csv("habit development.csv", header = FALSE)
```

```{r, include=FALSE}
habit <- data.frame(lapply(habit, function(x) as.numeric(as.character(x))))
```

```{r, include=FALSE}
colnames(habit) <- c("newhabit01",
                     "newhabit02",
                     "newhabit03",
                     "newhabit04",
                     "newhabit05",
                     "newhabit06",
                     "newhabit07",
                     "newhabit08",
                     "newhabit09"
                     ) 
```

ESEM with lavaan is very simple. We first specify a model that looks just like the one for EFA in lavaan. 

## ESEM Model 

```{r}
# these are exploratory blocks (you can give them any name), you'll need to specify them
esem_model <- 'efa("block1")*F1 =~ newhabit01 + newhabit02 + newhabit03 + newhabit04 + 
                                  newhabit05 + newhabit06 + newhabit07 + newhabit08 + 
                                  newhabit09
               efa("block1")*F2 =~ newhabit01 + newhabit02 + newhabit03 + newhabit04 + 
                                  newhabit05 + newhabit06 + newhabit07 + newhabit08 + 
                                  newhabit09'
```

The difference in the code is here. When fitting the model, we need to use ```rotation = geomin``` because ```geomin``` does not assume uncorrelated residuals. Like other oblique estimators, geomin allows latent factors to covary. 

Note: In addition to changing the estimator, we should tell lavaan to change the epsilon value so that it overrides its default of 0.001. This is important: Changing epsilon allows to change the size of the cross-loadings or of the factor correlations. The lower the epsilon, the greater the inter-factor correlations, the lower the cross-loadings, and the less accurate the associations between the constructs (Morin et al., in press). To optimize the estimate of the inter-factor correlations, Morin et al. recommend epsilon = .5.

**Important: By default, lavaan no longer allows changing the epsilon to values above .01, so the results will differ from those in Mplus and recommended values when using geomin. lavaan directly from GitHub may solve this, as their defaults are up to 1. To find lavaan defaults and how to change values: https://github.com/yrosseel/lavaan/blob/master/R/lav_options.R**

We have missing data so we're telling lavaan to use FIML to estimate missing values and we're using MLR as our estimator.

```{r, warning = FALSE}

esemfit <- cfa(model = esem_model,
                  data = habit,
                  rotation = "geomin",
                  rotation.args = list(geomin.epsilon = 0.5),
                  estimator = "MLR",
                  missing = "FIML")
```

```{r}
lavaan::summary(esemfit, 
        fit.measures = TRUE, 
        standardized = TRUE,
        rsquare = TRUE)
```

Notice that the correlation between the two latent variables is much lower in the ESEM model (*r* = .55) than in the EFA model (*r* = .71), and in the CFA model (*r* = .78) which makes sense given our use of geomin and specification of the value of epsilon. In the context of ESEM, it also makes sense that correlations would be lower in the ESEM model, as not allowing cross-loadings leads to inflation of the correlation between latent factors. 

Cross-loadings are fairly small in the ESEM solution. They range from .01-.14 for the first factor (and are all non-significant), and .11-36 for the second factor (all but one are significant). The factors are fairly well-defined in the ESEM solution: the loadings on f1 range from .38-.77 (M = .57), and on f2 range from .63-.73 (M = .69). Model fit is good, but it is poorer than that of the Bifactor CFA model when we consider the TLI and RMSEA (which tax low parsimony).

### Bifactor ESEM

To estimate a bifactor ESEM model, just add a general factor to the model with the same specifications as the two specific factors. 

```{r}
# these are exploratory blocks (you can give them any name), you'll need to specify them

biesem_model <- 'efa("block1")*F1 =~ newhabit01 + newhabit02 + newhabit03 + newhabit04 + 
                                  newhabit05 + newhabit06 + newhabit07 + newhabit08 + 
                                  newhabit09
                 efa("block1")*F2 =~ newhabit01 + newhabit02 + newhabit03 + newhabit04 + 
                                  newhabit05 + newhabit06 + newhabit07 + newhabit08 + 
                                  newhabit09  
                efa("block1")*g =~ newhabit01 + newhabit02 + newhabit03 + newhabit04 + 
                                  newhabit05 + newhabit06 + newhabit07 + newhabit08 + 
                                  newhabit09'
```

You'll need to change the rotation type to "bigeomin", which is one of the recommended rotations for bifactor ESEM (also what we're using in Mplus demo).

```{r, warning = FALSE}

biesemfit <- lavaan::cfa(model = biesem_model,
                  data = habit,
                  rotation = "bigeomin",
                  rotation.args = list(geomin.epsilon = .5),
                  estimator = "MLR",
                  missing = "FIML")
```

Compare the output with the one from Mplus. You'll notice that the standardized solution here is very similar to that in Mplus (under STDYX), but not exactly the same. This is likely because Mplus is using BI-GEOMIN orthogonal, in which the specific factors are uncorrelated with the general factor and with each other. Notice that lavaan is using "BIGEOMIN OBLIQUE" and that covariances/correlations are indeed non-zero (even if very small). Setting the factors to be orthogonal does not change lavaan's default to let the LV correlate.

```{r}
lavaan::summary(biesemfit, 
        fit.measures = TRUE, 
        standardized = TRUE,
        rsquare = TRUE)
```


```{r Create Simple Table, echo = FALSE}

df = c(36, 
       26, 
       24,
       27, 
       18,
       19)
CFI = c(.90,
        .96,
        .96,
        .95,
        .98, 
        .97)
TLI = c(.87,
        .94,
        .94,
        .93,
        .97, 
        .93)
RMSEA = c(.09, 
          .08,
          .08,
          .09,
          .05, 
          .07)
SRMR = c(.05, 
         .04, 
         .04,
         .13,
         .02, 
         .03)
Model = c("CFA: One factor", 
          "CFA: Two correlated factors", 
          "CFA: One factor plus method factor", 
          "CFA: second order", 
          "Bifactor", 
          "ESEM-geomin")
df <- data.frame(Model, df, CFI, TLI, RMSEA, SRMR)

knitr::kable(df) %>%
  kableExtra::kable_styling(full_width = F)
```
So, is the bifactor model the best fit? Does this mean we can treat this measure as a single score? Bifactor models can accommodate patterns of association in the data that are not accounted for when we use correlated-factor models. For example, in this measure, it would be unreasonable to assume that the last three items are completely unrelated to the first six - there's conceptual overlap between them and other items - but the correlated-factors model does not account for this, resulting in lower fit relative to the bifactor and ESEM models. 

This was a simple example, as what we're talking about (wording effects) is likely construct-irrelevant variance, or a methodological artifact. The purpose of this exercise - including both scripts - was to demonstrate the use of these tools to examine measure dimensionality. In this case, to determine whether it is tenable to use this measure as a composite index in an analysis. 

Importantly, *how* one treats the structure of a construct depends on more than fit. As you've read on Chapter 18 of the Handbook, better fit does **not** mean that the model is an accurate representation of the measurement structure for everyone (or even for most people in the sample) or an accurate representation of the "true" latent structure itself. This doesn't mean that these models aren't useful, but that they can help understand the sources of item variance and inform whether a measurement structure is tenable and interpretable/valid. These decisions must be made with justifications beyond statistical tests and fit coefficients.
